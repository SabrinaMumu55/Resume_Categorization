# -*- coding: utf-8 -*-
"""script main.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1oSLZM-BdIpHvN5IwaJ8qwhYwCm2eicRq
"""

import os
import pandas as pd
import nltk
from nltk.tokenize import word_tokenize
from sklearn.feature_extraction.text import TfidfVectorizer
import joblib

nltk.download('punkt')

import sys

"""**Loading the saved model and tf-idf vectorizer**"""

# Load the trained model using joblib
loaded_model = joblib.load("/content/RFC_model.joblib")

# Load the TF-IDF vectorizer used during training
tfidf_vectorizer = joblib.load("/content/tfidf_vectorizer.joblib")

"""**The code take as input a directory containing the resumes to be categorized.** Here, I have created a demo text.csv file that contanis only the sentences with a column name of "resume_text". I have also set the output directory named "Category" where the output files will be saved"""

# Input directory
input_directory = "/content/Input"

# Output directory
output_directory = "/content/Category"

# Create the output directory if it doesn't exist
if not os.path.exists(output_directory):
    os.makedirs(output_directory)

"""**Pre-processing fn**"""

# Preprocess the text data
def preprocess_text(text):
    tokenizer = nltk.WordPunctTokenizer()
    tokens = tokenizer.tokenize(text)
    preprocessed_text = ' '.join(tokens)
    return preprocessed_text

# Initialize a list to store categorized resume data
categorized_resumes = []

"""**Working on the csv file to predict the output and categorize the resumes**"""

# Iterate through each CSV file in the input directory
for filename in os.listdir(input_directory):
    if filename.endswith(".csv"):
        csv_file = os.path.join(input_directory, filename)

        # Load and preprocess the CSV file
        data = pd.read_csv(csv_file)

        # Iterate through each row
        for index, row in data.iterrows():
            resume_text = row["resume_text"]  # Replace with the actual column name
            predicted_category = loaded_model.predict(tfidf_vectorizer.transform([preprocess_text(resume_text)]))[0]

            # Create a folder for the category if it doesn't exist within the output directory
            category_folder = os.path.join(output_directory, predicted_category)
            if not os.path.exists(category_folder):
                os.makedirs(category_folder)

            # Write the processed resume text to a .txt file in the category folder
            resume_filename = f"resume_{index}.txt"
            resume_path = os.path.join(category_folder, resume_filename)
            with open(resume_path, "w") as file:
                file.write(preprocess_text(resume_text))

            # Store categorized resume data in the list
            categorized_resumes.append({"filename": resume_filename, "category": predicted_category})

# Create a DataFrame from the categorized resume data
categorized_df = pd.DataFrame(categorized_resumes)

# Write the categorized resume data to a CSV file
categorized_csv_path = os.path.join(output_directory, "categorized_resumes.csv")
categorized_df.to_csv(categorized_csv_path, index=False)

print("Completed.")