# -*- coding: utf-8 -*-
"""INTERVIEW.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1NhFsyMbBXevgesxl5k739WNju8FD1TAx

**Examine the dataset**
"""

import pandas as pd
import numpy as np

# While reading the csv file, some bad lines were giving error. So, I have skipped those bad
# lines to read the csv file

df= pd.read_csv("/content/Resume.csv", error_bad_lines= False)

df.head(10)

df.shape

# Dropping the columns I'm not going to use
df.drop(columns = ['ID', 'Resume_html'], inplace = True)

# Check how many null values are there in every column
df.isnull().sum()

# Cleaning null values in the data frame
df_clean= df.dropna()

# Checking the shape of the dataframe after removing null values
df_clean.shape

df_clean.head()

"""**Understand the distribution of different categories**"""

# Counting how many entries are there in different categories
cat_count = df_clean['Category'].value_counts()
print(cat_count)

total_count = cat_count.sum()
percentage_series = (cat_count / total_count) * 100

# Count the number of class in category column
print(len(cat_count))

num_classes = df_clean["Category"].nunique()
print(num_classes)



# Plotting the distribution

import matplotlib.pyplot as plt

cat_count.plot(kind='bar')
plt.xlabel('Categories')
plt.ylabel('Count')

# Title
plt.title('Category Distribution')

# Show the chart
plt.show()

# Create a pie chart
fig, ax = plt.subplots(figsize=(7, 7))
ax.pie(percentage_series, labels=percentage_series.index, autopct='%1.1f%%', startangle=0)
ax.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.


# Title
plt.title('Percentage Distribution of Categories')

# Show the chart
plt.show()

"""**Tokenization and splitting dataset**"""

import nltk
from nltk.tokenize import word_tokenize

nltk.download('punkt')

from sklearn.model_selection import train_test_split

# Split the dataset into training, validation, and test sets
train_data, test_data = train_test_split(df_clean, test_size=0.2, random_state=42)
train_data, val_data = train_test_split(df_clean, test_size=0.25, random_state=42)

print(train_data)

# Tokenize resumes
tokenizer = nltk.WordPunctTokenizer()
train_resumes = train_data['Resume_str'].apply(tokenizer.tokenize)
val_resumes = val_data['Resume_str'].apply(tokenizer.tokenize)
test_resumes = test_data['Resume_str'].apply(tokenizer.tokenize)

print(train_resumes)

# Convert tokenized resumes to strings
train_resumes = train_resumes.apply(' '.join)
val_resumes = val_resumes.apply(' '.join)
test_resumes = test_resumes.apply(' '.join)

print(train_resumes)

from sklearn.feature_extraction.text import TfidfVectorizer

# Convert text data to TF-IDF vectors
tfidf_vectorizer = TfidfVectorizer(max_features=5000)
X_train = tfidf_vectorizer.fit_transform(train_resumes)
X_val = tfidf_vectorizer.transform(val_resumes)
X_test = tfidf_vectorizer.transform(test_resumes)

print(X_train)

# Prepare the target labels
y_train = train_data['Category']
y_val = val_data['Category']
y_test = test_data['Category']

print(y_train)

"""**Implementing Model**"""

# Define hyperparameters to search through as I am gonoing to use Random Forest Classifier
param_grid = {
    'n_estimators': [150, 300, 350],
    'max_depth': [None, 10, 15, 30],
    'min_samples_split': [2, 5, 7],
    'min_samples_leaf': [1, 2, 6]
}

from sklearn.ensemble import RandomForestClassifier

# Initialize the Random Forest Classifier
rf_classifier = RandomForestClassifier(random_state=42)

from sklearn.model_selection import GridSearchCV

# Initialize GridSearch
grid_search = GridSearchCV(rf_classifier, param_grid, cv=3, n_jobs=-1)

# Fit the grid search to the data
grid_search.fit(X_train, y_train)

# Get the best parameters from the grid search
best_params = grid_search.best_params_

# Train the Random Forest classifier with the best parameters
best_rf_classifier = RandomForestClassifier(random_state=42, **best_params)
best_rf_classifier.fit(X_train, y_train)

"""**Result on Validation data**"""

# Predict on the validation set
y_val_pred = best_rf_classifier.predict(X_val)

from sklearn.metrics import classification_report

# Print classification report on validation set
print(classification_report(y_val, y_val_pred))

"""**Result on Test data**"""

# Predict on the test set
y_test_pred = best_rf_classifier.predict(X_test)

# Print classification report on test set
print("Test Set Classification Report:\n")
print(classification_report(y_test, y_test_pred))

from sklearn.metrics import confusion_matrix

# Calculate and print confusion matrix
conf_matrix = confusion_matrix(y_test, y_test_pred)
print("Confusion Matrix:\n")
print(conf_matrix)

import seaborn as sns

# Plotting the confusion matrix
plt.figure(figsize=(10, 8))
sns.set(font_scale=1.2)
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False,
            xticklabels=best_rf_classifier.classes_, yticklabels=best_rf_classifier.classes_)
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.xticks(rotation=45, ha='right')
plt.yticks(rotation=0)
plt.show()

"""**Saving Model and vectorizer**"""

import joblib

model_filename = 'RFC_model.joblib'
joblib.dump(best_rf_classifier, model_filename)
joblib.dump(tfidf_vectorizer, "tfidf_vectorizer.joblib")

"""**Visualization on the performance of the model**"""

from sklearn.metrics import accuracy_score, log_loss
from sklearn.model_selection import learning_curve

# Learning Curve
def plot_learning_curve(estimator, X, y):
    train_sizes, train_scores, test_scores = learning_curve(
        estimator, X, y, train_sizes=np.linspace(0.1, 1.0, 5), cv=3, n_jobs=-1
    )

    plt.figure(figsize=(4, 4))
    plt.plot(train_sizes, np.mean(train_scores, axis=1), label='Training Accuracy')
    plt.plot(train_sizes, np.mean(test_scores, axis=1), label='Validation Accuracy')
    plt.title('Learning Curve')
    plt.xlabel('Training Examples')
    plt.ylabel('Accuracy')
    plt.legend()
    plt.show()

# Learning Curve
plot_learning_curve(best_rf_classifier, X_train, y_train)

"""**any other curves like roc-auc, precision-recall gets messy figure as the model has 24 classes**"""

